# ProPaths System Architecture

> **30-Second Summary**: Bioinformatics web app that uses Gemini LLM to research protein-protein interactions (PPIs) from literature, stores results in PostgreSQL, and visualizes them as interactive D3.js force-directed graphs with evidence, functions, and biological cascades.

---

## Tech Stack

### Backend
- **Flask** (Python 3.10+) - Web server + API endpoints
- **PostgreSQL** (Railway) - Primary database with JSONB storage
- **SQLAlchemy** - ORM for database operations
- **Google Gemini 2.5 Pro** - LLM for research pipeline (with Google Search grounding)
- **Threading** - Background job execution with status tracking

### Frontend
- **D3.js v7** - Force-directed graph visualization
- **Vanilla JS** - UI interactions, data parsing, multi-job tracking
- **HTML/CSS** - Landing page, visualization page, modals
- **SessionStorage** - Job persistence across page navigation (viz page only)

### Infrastructure
- **Local Dev**: Flask server â†’ Railway PostgreSQL (via `DATABASE_PUBLIC_URL`)
- **Production**: Railway deployment (via `DATABASE_URL`)
- **File Cache**: `cache/` directory for backups, intermediate storage, pruned expansions

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER FLOW                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SEARCH (Frontend)                                             â”‚
â”‚    templates/index.html + static/script.js                       â”‚
â”‚    â†’ POST /api/query {"protein": "ATXN3"}                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RESEARCH PIPELINE (Backend - Background Thread)               â”‚
â”‚    app.py: run_full_job() â†’ runner.py: run_pipeline()            â”‚
â”‚                                                                   â”‚
â”‚    Phase 1: Interactor Discovery (3-8 rounds)                    â”‚
â”‚    â”œâ”€ Gemini + Google Search â†’ Find protein names               â”‚
â”‚    â””â”€ Classify direct vs indirect (cascade chains)              â”‚
â”‚                                                                   â”‚
â”‚    Phase 2: Function Discovery (3-8 rounds)                      â”‚
â”‚    â”œâ”€ Gemini â†’ Find mechanisms, evidence, PMIDs                 â”‚
â”‚    â””â”€ Build biological consequence chains                        â”‚
â”‚                                                                   â”‚
â”‚    Phase 3: Enrichment & Validation                              â”‚
â”‚    â”œâ”€ evidence_validator.py: Add quotes, validate PMIDs         â”‚
â”‚    â”œâ”€ claim_fact_checker.py: Verify claims (optional)           â”‚
â”‚    â”œâ”€ schema_validator.py: Fix structural issues                â”‚
â”‚    â”œâ”€ deduplicate_functions.py: Remove duplicates               â”‚
â”‚    â””â”€ interaction_metadata_generator.py: Generate metadata      â”‚
â”‚                                                                   â”‚
â”‚    Phase 4: Database Sync                                        â”‚
â”‚    â””â”€ db_sync.py: Write to PostgreSQL + file cache              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. DATABASE STORAGE (PostgreSQL)                                 â”‚
â”‚    models.py: Protein + Interaction tables                       â”‚
â”‚                                                                   â”‚
â”‚    Protein Table:                                                â”‚
â”‚    â””â”€ symbol, query_count, total_interactions                   â”‚
â”‚                                                                   â”‚
â”‚    Interaction Table (JSONB payload):                            â”‚
â”‚    â”œâ”€ protein_a_id < protein_b_id (canonical ordering)          â”‚
â”‚    â”œâ”€ direction, arrow, confidence (denormalized)                â”‚
â”‚    â””â”€ data: {functions[], evidence[], pmids[], ...}             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. VISUALIZATION (Frontend)                                      â”‚
â”‚    app.py: build_full_json_from_db() â†’ visualizer.py            â”‚
â”‚                                                                   â”‚
â”‚    Embedded JS (visualizer.js):                                  â”‚
â”‚    â”œâ”€ Parse snapshot_json (proteins[], interactions[])          â”‚
â”‚    â”œâ”€ Build D3 force graph (nodes + links)                      â”‚
â”‚    â”œâ”€ Render modals (evidence, functions, cascades)             â”‚
â”‚    â”œâ”€ Table view (sortable, filterable, exportable)             â”‚
â”‚    â””â”€ Chat interface (LLM-powered Q&A)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File Structure

### ğŸ”¹ Core Application (Root)
```
app.py                    # Flask routes, API endpoints, job orchestration (1878 LOC)
runner.py                 # Pipeline execution engine, LLM orchestration (3150 LOC)
models.py                 # SQLAlchemy ORM (Protein, Interaction tables)
visualizer.py             # HTML template generator with embedded D3.js
requirements.txt          # Python dependencies
.env                      # Secrets (GOOGLE_API_KEY, DATABASE_URL)
```

### ğŸ”¹ Pipeline Configuration
```
pipeline/
â”œâ”€â”€ config_gemini_MAXIMIZED.py  # Base pipeline (7 rounds interactors, 6 rounds functions)
â”œâ”€â”€ config_dynamic.py            # Dynamic config generator (supports variable rounds)
â”œâ”€â”€ types.py                     # StepConfig dataclass for pipeline steps
â””â”€â”€ pipeline.py                  # Legacy CLI wrapper (NOT used by web app)
```

### ğŸ”¹ Utils (Processing & Validation)
```
utils/
â”œâ”€â”€ db_sync.py                   # Database synchronization layer (canonical ordering)
â”œâ”€â”€ pruner.py                    # LLM/heuristic-based subgraph selection (expansion)
â”œâ”€â”€ evidence_validator.py        # Validate/enrich evidence, add quotes, normalize
â”œâ”€â”€ claim_fact_checker.py        # LLM-based fact-checking of claims
â”œâ”€â”€ schema_validator.py          # Pre/post validation, fix structural issues
â”œâ”€â”€ deduplicate_functions.py     # Remove duplicate function entries
â”œâ”€â”€ interaction_metadata_generator.py  # Generate interaction metadata
â”œâ”€â”€ clean_function_names.py      # Normalize function names
â”œâ”€â”€ update_cache_pmids.py        # Update/validate PMIDs in cached results
â”œâ”€â”€ pmid_extractor.py            # Standalone CLI tool for PMID lookup
â”œâ”€â”€ pubmed_match.py              # Paper search and similarity matching
â”œâ”€â”€ protein_database.py          # File-based protein cache (legacy, still used for helpers)
â”œâ”€â”€ step_logger.py               # Comprehensive logging for pipeline steps
â””â”€â”€ llm_response_parser.py       # Parse LLM JSON responses
```

### ğŸ”¹ Frontend (Web Interface)
```
static/
â”œâ”€â”€ script.js                    # Landing page logic, JobTracker class for multi-job tracking
â”œâ”€â”€ visualizer.js                # Graph rendering, VizJobTracker class, modals (6800+ LOC)
â”œâ”€â”€ styles.css                   # Shared site styles, job card styles
â””â”€â”€ viz-styles.css               # Visualization-specific styles, mini job chip styles

templates/
â””â”€â”€ index.html                   # Landing page template
```

### ğŸ”¹ Data Storage
```
cache/
â”œâ”€â”€ <PROTEIN>.json               # Full graph snapshots (fallback, intermediate)
â”œâ”€â”€ pruned/                      # Pruned subgraphs for expansion
â”‚   â””â”€â”€ <PARENT>_for_<PROTEIN>.json
â””â”€â”€ proteins/                    # Legacy file-based storage (being phased out)
    â””â”€â”€ <PROTEIN>/
        â”œâ”€â”€ metadata.json
        â””â”€â”€ interactions/
            â””â”€â”€ <PARTNER>.json
```

### ğŸ”¹ Testing
```
tests/
â”œâ”€â”€ test.py                      # Simple test runner
â””â”€â”€ test_server.py               # Server endpoint tests
```

### ğŸ”¹ Logs
```
Logs/
â””â”€â”€ <PROTEIN>/
    â””â”€â”€ <TIMESTAMP>/             # Pipeline execution logs
```

### âš ï¸ **LEGACY / TO REMOVE**
```
migrate_*.py                     # 12 one-time migration scripts (NO LONGER NEEDED)
â”œâ”€â”€ migrate_add_arrows.py
â”œâ”€â”€ migrate_add_chain_arrows.py
â”œâ”€â”€ migrate_add_function_context.py
â”œâ”€â”€ migrate_add_interaction_columns.py
â”œâ”€â”€ migrate_add_missing_columns.py
â”œâ”€â”€ migrate_cache.py
â”œâ”€â”€ migrate_deduplicate.py
â”œâ”€â”€ migrate_fix_direction_semantics.py
â”œâ”€â”€ migrate_fix_indirect_corruption.py
â”œâ”€â”€ migrate_indirect_chains.py
â”œâ”€â”€ migrate_restore_functions_from_cache.py
â””â”€â”€ migrate_to_postgres.py

sync_cache_to_db.py              # Manual sync tool (deprecated, db_sync.py is automatic)
visualizer copy.py               # Old backup (DELETE)
propaths_refactor_*.txt/md       # Refactor notes (archive or delete)
```

---

## Data Schemas

### 1. **Database Models** (`models.py`)

#### Protein Table
```python
class Protein(db.Model):
    id: int                      # Primary key
    symbol: str                  # e.g., "ATXN3" (unique, indexed)
    first_queried: datetime
    last_queried: datetime
    query_count: int
    total_interactions: int
    extra_data: JSONB            # Flexible metadata
```

#### Interaction Table
```python
class Interaction(db.Model):
    id: int                      # Primary key
    protein_a_id: int            # FK to proteins (always < protein_b_id)
    protein_b_id: int            # FK to proteins (canonical ordering)

    # Denormalized fields (for fast filtering)
    confidence: Numeric(3,2)     # 0.00 to 1.00
    direction: str               # 'a_to_b', 'b_to_a', 'bidirectional'
    arrow: str                   # 'binds', 'activates', 'inhibits', 'regulates'
    interaction_type: str        # 'direct' or 'indirect'
    upstream_interactor: str     # Upstream protein symbol (for indirect)
    mediator_chain: JSONB        # Chain path (for indirect)
    depth: int                   # 1=direct, 2+=indirect

    # FULL PAYLOAD (JSONB)
    data: JSONB                  # Complete interactor JSON (functions, evidence, PMIDs, etc.)

    # Discovery metadata
    discovered_in_query: str     # Which protein query found this
    discovery_method: str        # 'pipeline', 'requery', 'manual'
```

**Key Design Choice**: Canonical ordering (`protein_a_id < protein_b_id`) prevents duplicate storage of symmetric interactions. The `direction` field is converted to/from query-relative perspective during reads/writes.

### 2. **JSON Schemas**

#### snapshot_json (NEW FORMAT - Current)
```json
{
  "main": "ATXN3",
  "proteins": ["ATXN3", "VCP", "HDAC6", ...],
  "interactions": [
    {
      "source": "ATXN3",
      "target": "VCP",
      "type": "direct",
      "direction": "bidirectional",
      "arrow": "binds",
      "confidence": 0.85,
      "intent": "ubiquitination",
      "support_summary": "...",
      "pmids": ["17580304", ...],
      "evidence": [
        {
          "pmid": "17580304",
          "doi": "10.1074/...",
          "paper_title": "...",
          "authors": "...",
          "journal": "J Biol Chem",
          "year": 2007,
          "assay": "Co-IP",
          "species": "human",
          "relevant_quote": "..."
        }
      ],
      "functions": [
        {
          "function": "Protein Quality Control",
          "arrow": "activates",
          "cellular_process": "...",
          "effect_description": "...",
          "biological_consequence": [
            "ATXN3 â†’ VCP â†’ p97 ATPase â†’ Protein degradation"
          ],
          "specific_effects": ["..."],
          "pmids": ["..."],
          "evidence": [...]
        }
      ],
      "interaction_type": "direct",
      "upstream_interactor": null,
      "mediator_chain": [],
      "depth": 1
    },
    {
      "source": "VCP",
      "target": "HDAC6",
      "type": "shared",
      "_is_shared_link": true
    }
  ]
}
```

#### snapshot_json (OLD FORMAT - Legacy Fallback)
```json
{
  "main": "ATXN3",
  "interactors": [
    {
      "primary": "VCP",
      "direction": "bidirectional",
      "arrow": "binds",
      "functions": [...],
      "evidence": [...],
      "pmids": [...]
    }
  ]
}
```

**Key Design Choice**: New format separates proteins and interactions for cleaner graph rendering. Old format is automatically transformed by frontend (`visualizer.js:190-283`).

#### ctx_json (Context / Metadata)
```json
{
  "main": "ATXN3",
  "interactors": [...],           // Same as snapshot_json.interactions
  "interactor_history": ["VCP", "HDAC6", ...],
  "function_history": {
    "VCP": ["Autophagy", "ER-associated degradation", ...]
  },
  "function_batches": ["VCP", "HDAC6", ...],
  "search_history": ["ATXN3 protein interactions", ...]
}
```

### 3. **Interaction Types**

#### Direct Interactions (Physical)
- `interaction_type: "direct"`
- `upstream_interactor: null`
- `mediator_chain: []`
- `depth: 1`

#### Indirect Interactions (Cascade Chains)
- `interaction_type: "indirect"`
- `upstream_interactor: "VCP"` (mediator protein)
- `mediator_chain: ["VCP"]` or `["VCP", "LAMP2"]` (multi-hop)
- `depth: 2+` (number of hops from query protein)

#### Shared Links (Interactor â†” Interactor)
- `type: "shared"` or `_is_shared_link: true`
- Discovered when two interactors of the query protein also interact with each other
- Rendered as dashed lines in graph

---

## Key Components & Functions

### ğŸ”¹ **App.py** (Flask Server)
| Route | Purpose | Key Function |
|-------|---------|--------------|
| `POST /api/query` | Start research pipeline | `run_full_job()` (runner.py) |
| `GET /api/search/<protein>` | Check if protein exists in DB | Quick lookup, no research |
| `GET /api/status/<protein>` | Poll job status | Returns progress updates |
| `GET /api/results/<protein>` | Fetch full JSON | `build_full_json_from_db()` |
| `GET /api/visualize/<protein>` | Render visualization | `create_visualization_from_dict()` |
| `POST /api/expand/pruned` | Expand node (pruned subgraph) | `run_prune_job()` (utils/pruner.py) |
| `POST /api/chat` | Chat interface | `_build_chat_system_prompt()` |
| `POST /api/cancel/<protein>` | Cancel running job | Sets `cancel_event.set()` |

**Critical Functions**:
- `build_full_json_from_db(protein_symbol)`: Reconstructs complete JSON from PostgreSQL with canonical ordering conversion (app.py:353)
- `build_expansion_json_from_db(protein, visible_proteins)`: Builds expansion with auto-cross-linking (app.py:701)

### ğŸ”¹ **Runner.py** (Pipeline Engine)
| Function | Purpose | Location |
|----------|---------|----------|
| `run_full_job()` | Master orchestrator for background threads | Line 1807 |
| `run_pipeline()` | Execute LLM pipeline steps | Line 1055 |
| `run_requery_job()` | Re-query existing protein for new data | Line 2393 |
| `call_gemini_model()` | LLM API wrapper | Line 571 |
| `parse_json_output()` | Parse and merge LLM responses | Line 657 |
| `deep_merge_interactors()` | Intelligently merge new interactors into existing | Line 177 |
| `aggregate_function_arrows()` | Compute interaction-level arrow from functions | Line 382 |

**Pipeline Flow** (run_full_job):
1. Calculate total steps (for progress bar)
2. Get known interactions from DB (for exclusion context)
3. **Phase 1**: Run interactor/function discovery pipeline (3-8 rounds each)
4. **Phase 2**: Validate evidence (optional, can skip)
5. **Phase 3**: Generate metadata (optional)
6. **Phase 4**: Update PMIDs (optional)
7. **Phase 5**: Deduplicate functions (optional, can skip)
8. **Phase 6**: Clean function names (optional)
9. **Phase 7**: Fact-check claims (optional, can skip)
10. **Phase 8**: Validate schema consistency
11. **Phase 9**: Sync to PostgreSQL + file cache

### ğŸ”¹ **Utils/db_sync.py** (Database Layer)
| Function | Purpose | Location |
|----------|---------|----------|
| `sync_query_results()` | Write pipeline output to PostgreSQL | Line 75 |
| `sync_chain_relationships()` | Store indirect interaction chains | Line 333 |
| `_get_or_create_protein()` | Upsert protein entity | Line 203 |
| `_save_interaction()` | Upsert interaction with canonical ordering | Line 237 |
| `_validate_and_fix_chain()` | Detect and fix false chain assignments | Line 36 |

**Key Design Choice**: Uses SQLAlchemy transactions (`db.session.begin_nested()`) for atomic updates. Enforces canonical ordering (`protein_a_id < protein_b_id`) to prevent duplicates.

### ğŸ”¹ **Visualizer.js** (Frontend Graph)
| Function | Purpose | Location |
|----------|---------|----------|
| `VizJobTracker` (class) | Multi-job orchestration for viz page | Lines 3316-3763 |
| `initNetwork()` | Initialize D3 force simulation | Line 34 |
| `buildInitialGraph()` | Parse JSON, create nodes/links | Line 190 |
| `createSimulation()` | Configure D3 forces | Line ~800 |
| `expandNode()` | Expand interactor (fetch subgraph) | Line ~1200 |
| `collapseNode()` | Collapse expanded subgraph | Line ~1400 |
| `showInteractionModal()` | Display evidence modal | Line ~2000 |
| `showFunctionModal()` | Display function details | Line ~2200 |
| `fetchWithRetry()` | Resilient fetch with exponential backoff | Lines 3091-3105 |
| `saveToSessionStorage()` | Persist jobs across navigation | Lines 3595-3623 |
| `restoreFromSessionStorage()` | Restore jobs on page load | Lines 3684-3762 |

**Key Design Choice**: Frontend handles both NEW format (`proteins[]`, `interactions[]`) and LEGACY format (`interactors[]`) with automatic transformation (visualizer.js:208-283). Job tracking uses functional core + imperative shell pattern with sessionStorage persistence for cross-navigation reliability.

### ğŸ”¹ **Utils/pruner.py** (Subgraph Selection)
| Function | Purpose | Location |
|----------|---------|----------|
| `run_prune_job()` | Execute pruning (LLM or heuristic) | Line ~400 |
| `build_candidate_pack()` | Extract metadata for ranking | Line 82 |
| `heuristic_rank_candidates()` | Score candidates without LLM | Line ~300 |
| `is_pruned_fresh()` | Check if cached prune is valid | Line ~600 |

**Key Design Choice**: Heuristic scoring uses confidence, PMID count, recency, and mechanism overlap. LLM mode uses Gemini to rank by biological relevance (optional, slower).

---

## Critical Workflows

### ğŸ“Š **Workflow 1: Research Pipeline** (Most Important)
```
User â†’ POST /api/query {"protein": "ATXN3"}
  â†“
app.py: start_query()
  â””â”€ Threading.Thread(run_full_job) â†’ Background execution
     â†“
runner.py: run_full_job()
  â”œâ”€ Generate pipeline config (3-8 rounds each)
  â”œâ”€ Get known interactions from DB (for exclusion)
  â””â”€ run_pipeline()
     â”œâ”€ Phase 1: Interactor Discovery (7 steps)
     â”‚   â””â”€ Gemini + Google Search â†’ Find protein names + classify direct/indirect
     â”œâ”€ Phase 2: Function Discovery (6 steps)
     â”‚   â””â”€ Gemini â†’ Find mechanisms, evidence, PMIDs, biological cascades
     â””â”€ Return ctx_json + snapshot_json
  â†“
Validation & Enrichment Pipeline:
  â”œâ”€ evidence_validator.py: Add quotes, validate PMIDs
  â”œâ”€ claim_fact_checker.py: Verify claims (optional)
  â”œâ”€ schema_validator.py: Fix structural issues
  â”œâ”€ deduplicate_functions.py: Remove duplicates
  â””â”€ interaction_metadata_generator.py: Generate metadata
  â†“
db_sync.py: sync_query_results()
  â”œâ”€ Upsert Protein entity
  â”œâ”€ For each interactor:
  â”‚   â”œâ”€ Upsert partner Protein
  â”‚   â”œâ”€ Enforce canonical ordering (protein_a_id < protein_b_id)
  â”‚   â”œâ”€ Store FULL JSONB payload in Interaction.data
  â”‚   â””â”€ Update denormalized fields (confidence, direction, arrow)
  â””â”€ Commit transaction
  â†“
Cache to File (Fallback/Intermediate):
  â””â”€ Write cache/<PROTEIN>.json
  â†“
Update Job Status:
  â””â”€ jobs[protein]['status'] = 'complete'
```

**Key Files**:
- `app.py`: Routes + job orchestration
- `runner.py`: Pipeline engine + LLM calls
- `utils/db_sync.py`: PostgreSQL sync
- `utils/evidence_validator.py`: Evidence enrichment
- `pipeline/config_gemini_MAXIMIZED.py`: Pipeline configuration

### ğŸ“Š **Workflow 2: Fetching & Sending Data to Frontend**
```
User â†’ GET /api/visualize/ATXN3
  â†“
app.py: get_visualization()
  â””â”€ build_full_json_from_db("ATXN3")
     â”œâ”€ Query Protein table for main protein
     â”œâ”€ Query Interactions table (bidirectional due to canonical ordering)
     â”‚   â””â”€ WHERE protein_a_id = ATXN3.id OR protein_b_id = ATXN3.id
     â”œâ”€ For each interaction:
     â”‚   â”œâ”€ Extract FULL JSONB payload from data column
     â”‚   â”œâ”€ Convert canonical direction â†’ query-relative direction
     â”‚   â”‚   â””â”€ 'a_to_b' â†’ 'main_to_primary' OR 'primary_to_main' (based on query perspective)
     â”‚   â””â”€ Build interaction dict (source, target, type, arrow, functions[], evidence[])
     â”œâ”€ Query shared links (interactions BETWEEN interactors)
     â”‚   â””â”€ WHERE protein_a_id IN (interactor_ids) AND protein_b_id IN (interactor_ids)
     â””â”€ Return {snapshot_json: {main, proteins[], interactions[]}, ctx_json: {...}}
  â†“
visualizer.py: create_visualization_from_dict()
  â””â”€ Embed JSON into HTML template
  â””â”€ Return HTML with inline <script> containing SNAP = {...}
  â†“
Browser loads visualization page
  â†“
visualizer.js: initNetwork()
  â”œâ”€ Parse SNAP.proteins[] and SNAP.interactions[]
  â”œâ”€ Handle LEGACY format fallback (SNAP.interactors[] â†’ transform to new)
  â”œâ”€ Build D3 nodes[] and links[]
  â”‚   â””â”€ For each interaction:
  â”‚       â”œâ”€ Determine source/target based on direction
  â”‚       â”œâ”€ Attach functions[], evidence[], pmids[]
  â”‚       â””â”€ Set visual properties (arrow markers, colors, dash patterns)
  â””â”€ createSimulation()
     â”œâ”€ D3 force simulation (charge, collision, links)
     â””â”€ Render SVG (nodes, links, labels)
  â†“
User clicks interaction arrow or node
  â†“
showInteractionModal() or showFunctionModal()
  â””â”€ Display evidence, functions, biological cascades in modal
```

**Key Files**:
- `app.py`: build_full_json_from_db() (line 353)
- `models.py`: Protein, Interaction models
- `visualizer.py`: HTML template generator
- `static/visualizer.js`: D3 graph rendering (5736 LOC)

### ğŸ“Š **Workflow 3: Frontend Data Parsing & Rendering**
```
visualizer.js: buildInitialGraph() (line 190)
  â†“
Step 1: Detect format (NEW vs LEGACY)
  â”œâ”€ NEW: SNAP.proteins[] + SNAP.interactions[] exists
  â””â”€ LEGACY: SNAP.interactors[] exists
  â†“
Step 2a: NEW format (direct use)
  â”œâ”€ proteins = SNAP.proteins
  â””â”€ interactions = SNAP.interactions
  â†“
Step 2b: LEGACY format (transform)
  â”œâ”€ Extract proteins from SNAP.interactors[]
  â””â”€ Transform each interactor â†’ interaction:
     â”œâ”€ Convert query-relative direction â†’ link-absolute
     â”‚   â””â”€ 'primary_to_main' â†’ source=primary, target=main
     â”‚   â””â”€ 'main_to_primary' â†’ source=main, target=primary
     â”œâ”€ Override source for indirect interactions (use upstream_interactor)
     â””â”€ Attach all metadata (functions, evidence, pmids)
  â†“
Step 3: Build D3 graph data
  â”œâ”€ Create nodes[] (main + interactors)
  â”‚   â””â”€ Main node: larger radius, indigo gradient
  â”‚   â””â”€ Interactor nodes: smaller radius, gray gradient
  â”œâ”€ Create links[] from interactions
  â”‚   â”œâ”€ Determine arrow type (activates, inhibits, binds, regulates)
  â”‚   â”œâ”€ Set marker (arrow-activate, arrow-inhibit, arrow-binding, arrow-regulate)
  â”‚   â”œâ”€ Set stroke pattern:
  â”‚   â”‚   â”œâ”€ Solid: direct interactions
  â”‚   â”‚   â”œâ”€ Dashed: indirect interactions (cascade chains)
  â”‚   â”‚   â””â”€ Dotted: shared links (interactor â†” interactor)
  â”‚   â””â”€ Attach interaction data (for modal display)
  â””â”€ Calculate dynamic spacing (scales with interactor count)
  â†“
Step 4: Create D3 force simulation
  â”œâ”€ forceCenter: Pin main node at center
  â”œâ”€ forceManyBody: Repulsion between nodes (charge: -800)
  â”œâ”€ forceCollide: Prevent node overlap (radius + padding)
  â””â”€ forceLink: Spring force between connected nodes
  â†“
Step 5: Render SVG elements
  â”œâ”€ Links (paths with markers)
  â”œâ”€ Nodes (circles with labels)
  â””â”€ Function boxes (rounded rects attached to interactors)
  â†“
Step 6: Add interactivity
  â”œâ”€ Click node â†’ expandNode() or collapseNode()
  â”œâ”€ Click link â†’ showInteractionModal()
  â”œâ”€ Click function box â†’ showFunctionModal()
  â””â”€ Zoom/pan with d3.zoom()
```

**Key Files**:
- `static/visualizer.js`: All graph logic (6800+ LOC)
- `static/viz-styles.css`: Graph styles

### ğŸ“Š **Workflow 4: Multi-Job Tracking** (New System)
```
USER ACTIONS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Index Page (Full Cards):
  User starts query for PROTEIN1
    â†“
  JobTracker.addJob("PROTEIN1", config)
    â”œâ”€ Create job state (processing, 0%, startTime)
    â”œâ”€ Render full job card (70-80px height)
    â”œâ”€ Start independent polling (5s interval)
    â””â”€ Auto-navigate to viz page on completion
    â†“
  User starts query for PROTEIN2 (while PROTEIN1 running)
    â†“
  JobTracker.addJob("PROTEIN2", config)
    â”œâ”€ Check duplicate (shows confirm dialog if already exists)
    â”œâ”€ Add second job card to tracker
    â””â”€ Both jobs poll independently
    â†“
  User clicks "âˆ’" button (remove from tracker)
    â†“
  JobTracker.removeFromTracker()
    â””â”€ Job continues in background (backend keeps running)

Viz Page (Compact Chips):
  Page loads with SNAP.main = "PROTEIN1"
    â†“
  Auto-resume check:
    â””â”€ fetch(/api/status/PROTEIN1) â†’ if processing, add to VizJobTracker
    â†“
  SessionStorage restore:
    â”œâ”€ Read vizActiveJobs from sessionStorage
    â”œâ”€ For each saved job:
    â”‚   â”œâ”€ Skip if stale (>1 hour old)
    â”‚   â”œâ”€ Skip if already tracked (from auto-resume)
    â”‚   â”œâ”€ fetch(/api/status/{protein}) with retry
    â”‚   â””â”€ If still processing â†’ add to tracker
    â””â”€ Clean sessionStorage (keep only active jobs)
    â†“
  User searches for protein not in DB with running job:
    â†“
  handleQuery():
    â”œâ”€ fetch(/api/search/{protein}) â†’ not_found
    â”œâ”€ fetch(/api/status/{protein}) â†’ processing
    â””â”€ VizJobTracker.addJob() (stay on page, show notification)
    â†“
  User navigates to different protein:
    â†“
  VizJobTracker.saveToSessionStorage()
    â”œâ”€ Read existing saved jobs (merge, don't overwrite)
    â”œâ”€ Filter current processing jobs
    â””â”€ Save merged list to sessionStorage
    â†“
  Page unload:
    â””â”€ beforeunload event â†’ clear all polling intervals


POLLING LIFECYCLE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Every 5 seconds (per job):
  fetchWithRetry(/api/status/{protein})
    â”œâ”€ Timeout: 30s
    â”œâ”€ Retries: 3 (exponential backoff 1s, 2s, 4s)
    â””â”€ On success:
       â”œâ”€ Update progress (current/total)
       â”œâ”€ Update UI (progress bar, percentage)
       â””â”€ Handle status:
          â”œâ”€ complete â†’ stop polling, navigate/reload
          â”œâ”€ error â†’ show error, auto-remove after 5s
          â””â”€ cancelled â†’ show cancelled, auto-remove after 2s


CANCEL OPERATION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
User clicks "âœ•" button:
  JobTracker.cancelJob(protein)
    â”œâ”€ Stop polling FIRST (prevent race condition)
    â”œâ”€ Disable cancel button
    â”œâ”€ POST /api/cancel/{protein}
    â”œâ”€ On success:
    â”‚   â”œâ”€ Mark job as cancelled
    â”‚   â”œâ”€ Update UI
    â”‚   â””â”€ Remove after 2s delay
    â””â”€ On error:
       â”œâ”€ Re-enable cancel button
       â”œâ”€ Show error in UI
       â””â”€ Restart polling (job still running)


EDGE CASES HANDLED:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Multi-tab navigation â†’ Jobs merge in sessionStorage
âœ… Duplicate job detection â†’ Confirm dialog with cancel option
âœ… Stale job cleanup â†’ Auto-remove >1 hour old from storage
âœ… Network failures â†’ 3 retries with exponential backoff
âœ… Request timeouts â†’ 30s limit prevents hanging
âœ… Race conditions â†’ Polling stops before cancel request
âœ… Page unload â†’ All intervals cleared (no memory leaks)
âœ… Parallel restores â†’ Guard flag prevents concurrent execution
âœ… Auto-resume conflicts â†’ Skip jobs already tracked
```

**Key Files**:
- `static/script.js`: JobTracker class (lines 285-590)
- `static/visualizer.js`: VizJobTracker class (lines 3316-3763)
- `EDGE_CASE_FIXES.md`: Complete documentation of 9 fixes

**Architecture Pattern**:
- **Functional Core**: Pure state transformers (createJobState, updateJobProgress, etc.)
- **Imperative Shell**: DOM manipulation (createJobCard, updateJobCard, etc.)
- **Composition**: JobTracker orchestrates core + shell
- **Persistence**: SessionStorage (viz page only) with smart merge logic

---

## Development Setup

### Local Development
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Create .env file
GOOGLE_API_KEY=your_key_here
DATABASE_PUBLIC_URL=postgresql://...  # Railway external URL for local dev
DATABASE_URL=postgresql://...         # (Railway sets this automatically in prod)

# 3. Run Flask server
python app.py  # Starts on http://127.0.0.1:5000

# 4. Database tables auto-created on first run
# (db.create_all() in app.py startup)
```

### Production (Railway)
```bash
# Railway auto-sets DATABASE_URL (internal network)
# Push to main branch â†’ Railway auto-deploys
git push origin main
```

### File Cache vs Database
- **PostgreSQL**: Primary storage (canonical source of truth)
- **File cache (`cache/`)**: Used for:
  - Intermediate storage during pipeline execution
  - Fallback when database fails
  - Pruned expansions (`cache/pruned/`)
  - Local backups/snapshots

**Rule**: All queries write to BOTH PostgreSQL and file cache. Reads prioritize database, fall back to file.

---

## Where to Look: Quick Reference

### "Where is X defined/handled?"

| What | File | Function/Line |
|------|------|---------------|
| **Flask API routes** | app.py | Lines 114-1877 |
| **Research pipeline** | runner.py | run_full_job (1807), run_pipeline (1055) |
| **Database models** | models.py | Protein (18), Interaction (69) |
| **PostgreSQL sync** | utils/db_sync.py | sync_query_results (75) |
| **LLM calls** | runner.py | call_gemini_model (571) |
| **Evidence validation** | utils/evidence_validator.py | validate_and_enrich_evidence (~200) |
| **Fact checking** | utils/claim_fact_checker.py | fact_check_json (~100) |
| **Function deduplication** | utils/deduplicate_functions.py | deduplicate_payload (~50) |
| **Pruning/expansion** | utils/pruner.py | run_prune_job (~400) |
| **Frontend graph rendering** | static/visualizer.js | buildInitialGraph (190), createSimulation (~800) |
| **Graph interactions** | static/visualizer.js | expandNode (~1200), showInteractionModal (~2000) |
| **Table view** | static/visualizer.js | buildTableView (~3500) |
| **Chat interface** | app.py | POST /api/chat (1382) |
| **Job status tracking (backend)** | app.py | jobs dict + jobs_lock |
| **Multi-job tracking (index)** | static/script.js | JobTracker class (285-590) |
| **Multi-job tracking (viz)** | static/visualizer.js | VizJobTracker class (3316-3763) |
| **Job persistence** | static/visualizer.js | saveToSessionStorage (3595), restoreFromSessionStorage (3684) |
| **Fetch with retry** | static/script.js, visualizer.js | fetchWithRetry (lines 33-47, 3091-3105) |

### "I need to debug X"

| Issue | Files to Check | What to Look For |
|-------|----------------|------------------|
| **Pipeline fails** | runner.py, Logs/<PROTEIN>/ | LLM errors, JSON parse errors, cancellation |
| **Database errors** | app.py, utils/db_sync.py | Transaction rollbacks, unique constraint violations |
| **Graph not rendering** | static/visualizer.js (190-400) | Console errors, SNAP data format, empty proteins/interactions |
| **Shared links missing** | app.py:build_full_json_from_db (600-677) | Shared link query logic |
| **Indirect chains wrong** | utils/db_sync.py:_validate_and_fix_chain (36-73) | False chain detection |
| **Modal data incorrect** | static/visualizer.js (~2000-2500) | Modal rendering, evidence parsing |
| **Table view bugs** | static/visualizer.js (~3500-4500) | Table building, filtering, sorting |
| **Chat not working** | app.py:_build_chat_system_prompt (1382-1500) | Context building, LLM prompts |
| **Performance issues** | static/visualizer.js | Console.log statements (REMOVE), shared link rendering |
| **Jobs disappearing** | static/visualizer.js (3595-3762) | SessionStorage save/restore, merge logic |
| **Job polling stuck** | static/script.js, visualizer.js (_startPolling) | Retry logic, timeout, interval clearing |
| **Multi-tab job loss** | static/visualizer.js (3595-3623) | SessionStorage merge (not overwrite) |

### "I need to add a new feature"

| Feature | Primary Files | Secondary Files |
|---------|---------------|-----------------|
| **New pipeline step** | pipeline/config_gemini_MAXIMIZED.py | runner.py (add step handler) |
| **New API endpoint** | app.py | Add route, update static/script.js |
| **New validation** | utils/ (create new file) | runner.py (call in pipeline) |
| **New graph feature** | static/visualizer.js | static/viz-styles.css |
| **New modal** | static/visualizer.js | Add modal HTML + event handlers |
| **New DB column** | models.py | utils/db_sync.py (update sync logic) |

### "I need to understand X"

| Concept | Read These Files | Key Sections |
|---------|------------------|--------------|
| **JSON schemas** | CLAUDE.md (lines 52-166) | snapshot_json, ctx_json, interactor format |
| **Canonical ordering** | models.py (130-138), utils/db_sync.py (237-332) | Unique constraint, direction conversion |
| **Direct vs indirect** | CLAUDE.md (lines 87-92) | interaction_type, upstream_interactor, depth |
| **Arrow determination** | runner.py (382-550) | aggregate_function_arrows logic |
| **Pruning algorithm** | utils/pruner.py (82-200, ~300-400) | Candidate scoring, LLM ranking |
| **Evidence structure** | cache/LC3B.json (29-80) | Example evidence objects |

---

## Known Issues & Areas for Improvement

### ğŸ› Bugs (High Priority)
1. **Performance**: Heavy console.log statements in shared link rendering causing slowdowns
2. **UI Polish**: Some buttons not working, UI tweaks needed
3. **Table/Chat views**: Need verification that all graph data is displayed correctly

### ğŸ§¹ Code Cleanup (After Bug Fixes)
1. **Remove migration files**: 12 `migrate_*.py` files in root (no longer needed)
2. **Remove legacy backups**: `visualizer copy.py`, `propaths_refactor_*.txt/md`
3. **Extract frontend code**: `visualizer.py` should only be template generator, move JS to separate file
4. **Deduplicate functions**: Several repeated utility functions across backend files
5. **Better documentation**: Some complex functions lack docstrings

### ğŸ”® Future Enhancements
1. **Automated tests**: Currently only 2 unused tests in `tests/`
2. **Code organization**: Root directory has too many files
3. **Legacy cleanup**: Fully deprecate `cache/proteins/` file-based storage (keep `protein_database.py` helpers only)

---

## Additional Resources

- **CLAUDE.md**: Detailed project documentation (data contracts, API reference, development workflow)
- **ARYAN.md**: Co-founder's documentation
- **DEPLOYMENT.md**: Railway deployment guide
- **Logs/**: Pipeline execution logs (useful for debugging LLM behavior)
- **Railway Dashboard**: https://railway.app/ (production database, deployment logs)

---

## Quick Commands

```bash
# Start local server
python app.py

# Check database status
# (Look at startup logs for protein/interaction counts)

# Run migration (DEPRECATED - don't use unless specifically needed)
# python migrate_*.py

# View logs for a protein
ls -la Logs/<PROTEIN>/

# Clear cache (nuclear option - forces re-query)
rm -rf cache/<PROTEIN>.json
```

---

**Last Updated**: 2025-01-17
**Recent Changes**: Added multi-job tracking system with sessionStorage persistence, edge case fixes, and resilient fetch utilities
**Maintainers**: Kazi
**Production**: Railway (PostgreSQL + Flask deployment)
**LLM**: Google Gemini 2.5 Pro with Google Search grounding
